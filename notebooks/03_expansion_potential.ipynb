{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansion Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from src.dataloader import load_and_save_data\n",
    "from src.optimiser import main\n",
    "from src.client_generator import add_new_clients_and_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"../data/ChallengeXHEC23022024.xlsx\"\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "\n",
    "jan24_df = pd.read_excel(excel_data, sheet_name=\"JAN24\")\n",
    "clients_df = pd.read_excel(excel_data, sheet_name=\"clients\")\n",
    "intervenants_df = pd.read_excel(excel_data, sheet_name=\"intervenants\")\n",
    "\n",
    "\n",
    "paris_center_coords = {\"Latitude\": 48.864716, \"Longitude\": 2.349014}\n",
    "\n",
    "\n",
    "clients_df[\"Distance from Paris Center\"] = np.sqrt(\n",
    "    (clients_df[\"Latitude\"] - paris_center_coords[\"Latitude\"]) ** 2\n",
    "    + (clients_df[\"Longitude\"] - paris_center_coords[\"Longitude\"]) ** 2\n",
    ")\n",
    "\n",
    "# Convert service times to datetime\n",
    "fixed_date = pd.Timestamp(\"2024-01-01\")\n",
    "jan24_df[\"Heure de début\"] = pd.to_datetime(\n",
    "    fixed_date.strftime(\"%Y-%m-%d\")\n",
    "    + \" \"\n",
    "    + jan24_df[\"Heure de début\"].astype(str)\n",
    ")\n",
    "jan24_df[\"Heure de fin\"] = pd.to_datetime(\n",
    "    fixed_date.strftime(\"%Y-%m-%d\")\n",
    "    + \" \"\n",
    "    + jan24_df[\"Heure de fin\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "jan24_df[\"Service Duration\"] = (\n",
    "    jan24_df[\"Heure de fin\"] - jan24_df[\"Heure de début\"]\n",
    ").dt.total_seconds() / 60  # In Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_service_count = jan24_df.groupby(\"ID Client\")[\"Prestation\"].count()\n",
    "client_service_duration = jan24_df.groupby(\"ID Client\")[\n",
    "    \"Service Duration\"\n",
    "].sum()\n",
    "\n",
    "combined_client_data = clients_df.set_index(\"ID Client\").join(\n",
    "    [client_service_count, client_service_duration], how=\"left\"\n",
    ")\n",
    "combined_client_data.rename(\n",
    "    columns={\n",
    "        \"Prestation\": \"Total Services\",\n",
    "        \"Service Duration\": \"Total Service Duration\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client_data[\"Average Service Duration\"] = (\n",
    "    combined_client_data[\"Total Service Duration\"]\n",
    "    / combined_client_data[\"Total Services\"]\n",
    ")\n",
    "service_variety = jan24_df.groupby(\"ID Client\")[\"Prestation\"].nunique()\n",
    "\n",
    "combined_client_data = combined_client_data.join(service_variety, how=\"left\")\n",
    "combined_client_data.rename(\n",
    "    columns={\"Prestation\": \"Service Variety\"}, inplace=True\n",
    ")\n",
    "\n",
    "total_days_in_january = jan24_df[\"Date\"].nunique()\n",
    "combined_client_data[\"Service Frequency\"] = (\n",
    "    combined_client_data[\"Total Services\"] / total_days_in_january\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_clustering = combined_client_data[\n",
    "    [\n",
    "        \"Distance from Paris Center\",\n",
    "        \"Total Services\",\n",
    "        \"Total Service Duration\",\n",
    "        \"Average Service Duration\",\n",
    "        \"Service Variety\",\n",
    "        \"Service Frequency\",\n",
    "    ]\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_for_clustering)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "kmeans.fit(features_scaled)\n",
    "\n",
    "\n",
    "combined_client_data[\"Cluster\"] = kmeans.labels_\n",
    "\n",
    "combined_client_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = combined_client_data[\"Cluster\"].value_counts().sort_index()\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster_data = combined_client_data[combined_client_data[\"Cluster\"] == i]\n",
    "    print(f\"Cluster {i} Statistics:\")\n",
    "    print(cluster_data.describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_df = clients_df.join(combined_client_data[\"Cluster\"], on=\"ID Client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Sessions from Clients\n",
    "- From clients in the similar group, create a client using random properties of them\n",
    "- Groupby client group and prestation. Find the number of times these events occured. According to the average number of times it has occured during the period. Create these events by random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan24_df = pd.read_excel(excel_data, sheet_name=\"JAN24\")\n",
    "df = pd.merge(jan24_df, clients_df, how=\"left\", on=\"ID Client\")\n",
    "df[\"weekday\"] = df[\"Date\"].dt.weekday\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model events with a Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "For each cluster, we know: \n",
    "- How many events a given day has\n",
    "- Probability of the prestation.\n",
    "\n",
    "For every day, we assign prestations based on probabilities. \n",
    "\n",
    "### Method 2\n",
    "\n",
    "For each cluster: \n",
    "1) get the total number of events in the whole month per client\n",
    "2) Calculate the probabilities of events to occur on a given day (Vector of length 31)\n",
    "    - Model this as a poisson distribution\n",
    "3) With this poisson distribution, for a new client, get a new series of events in the month distributed to days.\n",
    "4) After we have the events for the client, assign them prestations based on empirical probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_events_per_cluster = (\n",
    "    df.groupby([\"Cluster\", \"ID Client\"])[\"Prestation\"]\n",
    "    .count()\n",
    "    .groupby(\"Cluster\")\n",
    "    .mean()\n",
    "    .apply(np.round)\n",
    "    .astype(int)\n",
    ")\n",
    "mean_events_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_probabilities = df.groupby(\"Cluster\")[\"Date\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_counts_per_day = (\n",
    "    df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "    / df.groupby(\"Cluster\")[\"ID Client\"].nunique()\n",
    ")\n",
    "mean_events_per_cluster = event_counts_per_day.groupby(level=0).mean()\n",
    "mean_events_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_group = 2\n",
    "pd.Series(\n",
    "    poisson.rvs(\n",
    "        mu=mean_events_per_cluster.loc[persona_group],\n",
    "        size=df[\"Date\"].nunique(),\n",
    "    ),\n",
    "    index=df[\"Date\"].unique(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_probabilities = df.groupby(\"Cluster\")[\"Prestation\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "# event_frequencies.groupby(level=0).sum()\n",
    "event_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each persona type, we write a function that:\n",
    "    - Generates a new client ID\n",
    "    - Randomly chooses the location from one of the clients \n",
    "    - Generates similar number of events for every persona - client combo (Uniform random that has +-3 events)\n",
    "    - For each event, chooses a pre-existing time and adds a +- 30 minute uniform to start time and multiplies the duration with a random factor\n",
    "- Add client ID and Coordinates to clients_df\n",
    "- Add All sessions to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_group = 2\n",
    "\n",
    "df_clients = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=1)\n",
    "df_sessions = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=0)\n",
    "df_persona = df[df[\"Cluster\"] == persona_group].copy()\n",
    "\n",
    "\n",
    "# Generate key for new client\n",
    "# new_client_id = np.random.randint(10000000, 100000000)\n",
    "\n",
    "# Take a random location for client\n",
    "client_loc = df_persona[[\"ID Client\", \"Latitude\", \"Longitude\"]].sample(1)\n",
    "new_client_id = client_loc.pop(\"ID Client\").iloc[0]\n",
    "client_loc = {k: list(v.values())[0] for k, v in client_loc.to_dict().items()}\n",
    "\n",
    "# Join new client to client dataset\n",
    "new_client = pd.DataFrame(\n",
    "    {\"ID Client\": new_client_id} | client_loc, index=[len(df_clients)]\n",
    ")\n",
    "new_df_clients = pd.concat([df_clients, new_client])\n",
    "\n",
    "\n",
    "# Get event counts with a Poisson Distribution\n",
    "event_counts = df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "event_counts = event_counts.loc[persona_group]\n",
    "\n",
    "event_counts_per_day = (\n",
    "    df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "    / df.groupby(\"Cluster\")[\"ID Client\"].nunique()\n",
    ")\n",
    "mu = event_counts_per_day.loc[persona_group]\n",
    "sim_event_counts = pd.Series(\n",
    "    poisson.rvs(\n",
    "        mu=mean_events_per_cluster.loc[persona_group],\n",
    "        size=df[\"Date\"].nunique(),\n",
    "    ),\n",
    "    index=df[\"Date\"].unique(),\n",
    ")\n",
    "\n",
    "\n",
    "# Get event probabilities\n",
    "probs = event_probabilities.loc[persona_group]\n",
    "\n",
    "# Generate a random event until all events are complete\n",
    "new_events = pd.DataFrame(columns=df_sessions.columns)\n",
    "\n",
    "\n",
    "## Choose a random event start time\n",
    "for date, count in sim_event_counts.to_frame().iterrows():\n",
    "    count = count.iloc[0]\n",
    "    if count == 0:\n",
    "        continue\n",
    "\n",
    "    # Assign events based on probabilities\n",
    "    events = np.random.choice(\n",
    "        event_probabilities.loc[persona_group].index,\n",
    "        count,\n",
    "        p=event_probabilities.loc[persona_group].values,\n",
    "    )\n",
    "\n",
    "    # From these events, sample times\n",
    "    times = pd.DataFrame(\n",
    "        [\n",
    "            df_persona[df_persona[\"Prestation\"] == event][\n",
    "                [\"Heure de début\", \"Heure de fin\"]\n",
    "            ]\n",
    "            .sample(1)\n",
    "            .squeeze()\n",
    "            .to_list()\n",
    "            for event in events\n",
    "        ],\n",
    "        columns=[\"Heure de début\", \"Heure de fin\"],\n",
    "    )\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"ID Client\": [new_client_id] * count,\n",
    "            \"ID Intervenant\": [\n",
    "                intervenants_df[\"ID Intervenant\"].sample(1).iloc[0]\n",
    "            ]\n",
    "            * count,\n",
    "            \"Date\": [date] * count,\n",
    "            \"Heure de début\": times[\"Heure de début\"].to_list(),\n",
    "            \"Heure de fin\": times[\"Heure de fin\"].to_list(),\n",
    "            \"Prestation\": events,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    new_events = pd.concat([new_events, new_row])\n",
    "\n",
    "\n",
    "new_df_sessions = (\n",
    "    pd.concat([df_sessions, new_events])\n",
    "    .sort_values(by=\"Date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "new_df_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_event_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "- Generate random scenarios of clients for n_clients equal to 1,2,3,4,5\n",
    "- Run the optimisation and see which ones have a feasible scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients, df_sessions = add_new_clients_and_sessions(\n",
    "    5,\n",
    "    excel_file=\"data/ChallengeXHEC23022024.xlsx\",\n",
    "    random_client_segment=False,\n",
    "    client_personas_sequence=\"13212\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_save_data(generate_new_clients=False, **{\"n_clients\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(include_availability=False, filter_for_competence=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
