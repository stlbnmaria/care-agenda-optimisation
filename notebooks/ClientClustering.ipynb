{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from src.dataloader import load_and_save_data\n",
    "from src.optimiser import main\n",
    "from src.client_generator import add_new_clients_and_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"../data/ChallengeXHEC23022024.xlsx\"\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "\n",
    "jan24_df = pd.read_excel(excel_data, sheet_name=\"JAN24\")\n",
    "clients_df = pd.read_excel(excel_data, sheet_name=\"clients\")\n",
    "intervenants_df = pd.read_excel(excel_data, sheet_name=\"intervenants\")\n",
    "\n",
    "\n",
    "paris_center_coords = {\"Latitude\": 48.864716, \"Longitude\": 2.349014}\n",
    "\n",
    "\n",
    "clients_df[\"Distance from Paris Center\"] = np.sqrt(\n",
    "    (clients_df[\"Latitude\"] - paris_center_coords[\"Latitude\"]) ** 2\n",
    "    + (clients_df[\"Longitude\"] - paris_center_coords[\"Longitude\"]) ** 2\n",
    ")\n",
    "\n",
    "# Convert service times to datetime\n",
    "fixed_date = pd.Timestamp(\"2024-01-01\")\n",
    "jan24_df[\"Heure de début\"] = pd.to_datetime(\n",
    "    fixed_date.strftime(\"%Y-%m-%d\")\n",
    "    + \" \"\n",
    "    + jan24_df[\"Heure de début\"].astype(str)\n",
    ")\n",
    "jan24_df[\"Heure de fin\"] = pd.to_datetime(\n",
    "    fixed_date.strftime(\"%Y-%m-%d\")\n",
    "    + \" \"\n",
    "    + jan24_df[\"Heure de fin\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "jan24_df[\"Service Duration\"] = (\n",
    "    jan24_df[\"Heure de fin\"] - jan24_df[\"Heure de début\"]\n",
    ").dt.total_seconds() / 60  # In Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_service_count = jan24_df.groupby(\"ID Client\")[\"Prestation\"].count()\n",
    "client_service_duration = jan24_df.groupby(\"ID Client\")[\n",
    "    \"Service Duration\"\n",
    "].sum()\n",
    "\n",
    "combined_client_data = clients_df.set_index(\"ID Client\").join(\n",
    "    [client_service_count, client_service_duration], how=\"left\"\n",
    ")\n",
    "combined_client_data.rename(\n",
    "    columns={\n",
    "        \"Prestation\": \"Total Services\",\n",
    "        \"Service Duration\": \"Total Service Duration\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client_data[\"Average Service Duration\"] = (\n",
    "    combined_client_data[\"Total Service Duration\"]\n",
    "    / combined_client_data[\"Total Services\"]\n",
    ")\n",
    "service_variety = jan24_df.groupby(\"ID Client\")[\"Prestation\"].nunique()\n",
    "\n",
    "combined_client_data = combined_client_data.join(service_variety, how=\"left\")\n",
    "combined_client_data.rename(\n",
    "    columns={\"Prestation\": \"Service Variety\"}, inplace=True\n",
    ")\n",
    "\n",
    "total_days_in_january = jan24_df[\"Date\"].nunique()\n",
    "combined_client_data[\"Service Frequency\"] = (\n",
    "    combined_client_data[\"Total Services\"] / total_days_in_january\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_clustering = combined_client_data[\n",
    "    [\n",
    "        \"Distance from Paris Center\",\n",
    "        \"Total Services\",\n",
    "        \"Total Service Duration\",\n",
    "        \"Average Service Duration\",\n",
    "        \"Service Variety\",\n",
    "        \"Service Frequency\",\n",
    "    ]\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_for_clustering)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "kmeans.fit(features_scaled)\n",
    "\n",
    "\n",
    "combined_client_data[\"Cluster\"] = kmeans.labels_\n",
    "\n",
    "combined_client_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = combined_client_data[\"Cluster\"].value_counts().sort_index()\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster_data = combined_client_data[combined_client_data[\"Cluster\"] == i]\n",
    "    print(f\"Cluster {i} Statistics:\")\n",
    "    print(cluster_data.describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_df = clients_df.join(combined_client_data[\"Cluster\"], on=\"ID Client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Sessions from Clients\n",
    "- From clients in the similar group, create a client using random properties of them\n",
    "- Groupby client group and prestation. Find the number of times these events occured. According to the average number of times it has occured during the period. Create these events by random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan24_df = pd.read_excel(excel_data, sheet_name=\"JAN24\")\n",
    "df = pd.merge(jan24_df, clients_df, how=\"left\", on=\"ID Client\")\n",
    "df[\"weekday\"] = df[\"Date\"].dt.weekday\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model events with a Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "For each cluster, we know: \n",
    "- How many events a given day has\n",
    "- Probability of the prestation.\n",
    "\n",
    "For every day, we assign prestations based on probabilities. \n",
    "\n",
    "### Method 2\n",
    "\n",
    "For each cluster: \n",
    "1) get the total number of events in the whole month per client\n",
    "2) Calculate the probabilities of events to occur on a given day (Vector of length 31)\n",
    "    - Model this as a poisson distribution\n",
    "3) With this poisson distribution, for a new client, get a new series of events in the month distributed to days.\n",
    "4) After we have the events for the client, assign them prestations based on empirical probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_events_per_cluster = (\n",
    "    df.groupby([\"Cluster\", \"ID Client\"])[\"Prestation\"]\n",
    "    .count()\n",
    "    .groupby(\"Cluster\")\n",
    "    .mean()\n",
    "    .apply(np.round)\n",
    "    .astype(int)\n",
    ")\n",
    "mean_events_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_probabilities = df.groupby(\"Cluster\")[\"Date\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_counts_per_day = (\n",
    "    df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "    / df.groupby(\"Cluster\")[\"ID Client\"].nunique()\n",
    ")\n",
    "mean_events_per_cluster = event_counts_per_day.groupby(level=0).mean()\n",
    "mean_events_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_group = 2\n",
    "pd.Series(\n",
    "    poisson.rvs(\n",
    "        mu=mean_events_per_cluster.loc[persona_group],\n",
    "        size=df[\"Date\"].nunique(),\n",
    "    ),\n",
    "    index=df[\"Date\"].unique(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_probabilities = df.groupby(\"Cluster\")[\"Prestation\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "# event_frequencies.groupby(level=0).sum()\n",
    "event_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each persona type, we write a function that:\n",
    "    - Generates a new client ID\n",
    "    - Randomly chooses the location from one of the clients \n",
    "    - Generates similar number of events for every persona - client combo (Uniform random that has +-3 events)\n",
    "    - For each event, chooses a pre-existing time and adds a +- 30 minute uniform to start time and multiplies the duration with a random factor\n",
    "- Add client ID and Coordinates to clients_df\n",
    "- Add All sessions to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_group = 2\n",
    "\n",
    "df_clients = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=1)\n",
    "df_sessions = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=0)\n",
    "df_persona = df[df[\"Cluster\"] == persona_group].copy()\n",
    "\n",
    "\n",
    "# Generate key for new client\n",
    "# new_client_id = np.random.randint(10000000, 100000000)\n",
    "\n",
    "# Take a random location for client\n",
    "client_loc = df_persona[[\"ID Client\", \"Latitude\", \"Longitude\"]].sample(1)\n",
    "new_client_id = client_loc.pop(\"ID Client\").iloc[0]\n",
    "client_loc = {k: list(v.values())[0] for k, v in client_loc.to_dict().items()}\n",
    "\n",
    "# Join new client to client dataset\n",
    "new_client = pd.DataFrame(\n",
    "    {\"ID Client\": new_client_id} | client_loc, index=[len(df_clients)]\n",
    ")\n",
    "new_df_clients = pd.concat([df_clients, new_client])\n",
    "\n",
    "\n",
    "# Get event counts with a Poisson Distribution\n",
    "event_counts = df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "event_counts = event_counts.loc[persona_group]\n",
    "\n",
    "event_counts_per_day = (\n",
    "    df.groupby([\"Cluster\", \"Date\"])[\"Prestation\"].count()\n",
    "    / df.groupby(\"Cluster\")[\"ID Client\"].nunique()\n",
    ")\n",
    "mu = event_counts_per_day.loc[persona_group]\n",
    "sim_event_counts = pd.Series(\n",
    "    poisson.rvs(\n",
    "        mu=mean_events_per_cluster.loc[persona_group],\n",
    "        size=df[\"Date\"].nunique(),\n",
    "    ),\n",
    "    index=df[\"Date\"].unique(),\n",
    ")\n",
    "\n",
    "\n",
    "# Get event probabilities\n",
    "probs = event_probabilities.loc[persona_group]\n",
    "\n",
    "# Generate a random event until all events are complete\n",
    "new_events = pd.DataFrame(columns=df_sessions.columns)\n",
    "\n",
    "\n",
    "## Choose a random event start time\n",
    "for date, count in sim_event_counts.to_frame().iterrows():\n",
    "    count = count.iloc[0]\n",
    "    if count == 0:\n",
    "        continue\n",
    "\n",
    "    # Assign events based on probabilities\n",
    "    events = np.random.choice(\n",
    "        event_probabilities.loc[persona_group].index,\n",
    "        count,\n",
    "        p=event_probabilities.loc[persona_group].values,\n",
    "    )\n",
    "\n",
    "    # From these events, sample times\n",
    "    times = pd.DataFrame(\n",
    "        [\n",
    "            df_persona[df_persona[\"Prestation\"] == event][\n",
    "                [\"Heure de début\", \"Heure de fin\"]\n",
    "            ]\n",
    "            .sample(1)\n",
    "            .squeeze()\n",
    "            .to_list()\n",
    "            for event in events\n",
    "        ],\n",
    "        columns=[\"Heure de début\", \"Heure de fin\"],\n",
    "    )\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"ID Client\": [new_client_id] * count,\n",
    "            \"ID Intervenant\": [\n",
    "                intervenants_df[\"ID Intervenant\"].sample(1).iloc[0]\n",
    "            ]\n",
    "            * count,\n",
    "            \"Date\": [date] * count,\n",
    "            \"Heure de début\": times[\"Heure de début\"].to_list(),\n",
    "            \"Heure de fin\": times[\"Heure de fin\"].to_list(),\n",
    "            \"Prestation\": events,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    new_events = pd.concat([new_events, new_row])\n",
    "\n",
    "\n",
    "new_df_sessions = (\n",
    "    pd.concat([df_sessions, new_events])\n",
    "    .sort_values(by=\"Date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "new_df_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_event_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_group = \"c\"\n",
    "\n",
    "df_clients = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=1)\n",
    "df_sessions = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=0)\n",
    "df_persona = df[df[\"client_persona\"] == persona_group].copy()\n",
    "\n",
    "\n",
    "# Generate key for new client\n",
    "new_client_id = np.random.randint(10000000, 100000000)\n",
    "\n",
    "# Take a random location for client\n",
    "client_loc = df_persona[[\"Latitude\", \"Longitude\"]].sample(1).to_dict()\n",
    "client_loc = {k: list(v.values())[0] for k, v in client_loc.items()}\n",
    "\n",
    "# Join new client to client dataset\n",
    "new_client = pd.DataFrame(\n",
    "    {\"ID Client\": new_client_id} | client_loc, index=[len(df_clients)]\n",
    ")\n",
    "new_df_clients = pd.concat([df_clients, new_client])\n",
    "\n",
    "# Get event freqs\n",
    "freqs = event_frequencies.loc[persona_group].apply(\n",
    "    lambda x: max(1, x + np.random.randint(-1, 1))\n",
    ")\n",
    "\n",
    "\n",
    "# Generate a random event until all events are complete\n",
    "new_events = pd.DataFrame(columns=df_sessions.columns)\n",
    "\n",
    "\n",
    "## Choose a random event start time\n",
    "for (date, prest), count in freqs.to_frame().iterrows():\n",
    "    # display(i[1], count.iloc[0])\n",
    "    count = count.iloc[0]\n",
    "\n",
    "    # Don't need to implement the above\n",
    "    # Convert time to same format as Heure de debut after randomly adding a term to it\n",
    "    # times = df_persona[df_persona[\"Prestation\"]==prest][[\"Start_time\", \"Duration\"]].sample(count)\n",
    "\n",
    "    times = df_persona[df_persona[\"Prestation\"] == prest][\n",
    "        [\"Heure de début\", \"Heure de fin\"]\n",
    "    ].sample(count)\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"ID Client\": [new_client_id] * count,\n",
    "            \"ID Intervenant\": [\n",
    "                intervenants_df[\"ID Intervenant\"].sample(1).iloc[0]\n",
    "            ]\n",
    "            * count,\n",
    "            \"Date\": [date] * count,\n",
    "            \"Heure de début\": times[\"Heure de début\"].to_list(),\n",
    "            \"Heure de fin\": times[\"Heure de fin\"].to_list(),\n",
    "            \"Prestation\": [prest] * count,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    new_events = pd.concat([new_events, new_row])\n",
    "\n",
    "\n",
    "new_df_sessions = (\n",
    "    pd.concat([df_sessions, new_events])\n",
    "    .sort_values(by=\"Date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "new_df_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(dictionary, value):\n",
    "    for key, values in dictionary.items():\n",
    "        if value in values:\n",
    "            return key\n",
    "    return np.nan  # If the value is not found in any list\n",
    "\n",
    "\n",
    "def get_client_segments(file_path: str = \"../data/ChallengeXHEC23022024.xlsx\"):\n",
    "    excel_data = pd.ExcelFile(file_path)\n",
    "    jan24_df = pd.read_excel(excel_data, sheet_name=\"JAN24\")\n",
    "    clients_df = pd.read_excel(excel_data, sheet_name=\"clients\")\n",
    "\n",
    "    # Analyzing client data to create personas\n",
    "    paris_center_coords = {\"Latitude\": 48.864716, \"Longitude\": 2.349014}\n",
    "\n",
    "    # Calculating the distance of each client from the Paris city center\n",
    "    clients_df[\"Distance from Paris Center\"] = (\n",
    "        (clients_df[\"Latitude\"] - paris_center_coords[\"Latitude\"]) ** 2\n",
    "        + (clients_df[\"Longitude\"] - paris_center_coords[\"Longitude\"]) ** 2\n",
    "    ) ** 0.5\n",
    "    client_service_summary = (\n",
    "        jan24_df.groupby(\"ID Client\")[\"Prestation\"]\n",
    "        .value_counts()\n",
    "        .unstack(fill_value=0)\n",
    "    )\n",
    "    combined_client_data = clients_df.join(\n",
    "        client_service_summary, on=\"ID Client\"\n",
    "    )\n",
    "    combined_client_data[\"Distance from Paris Center\"] = clients_df[\n",
    "        \"Distance from Paris Center\"\n",
    "    ]\n",
    "\n",
    "    # Persona A: Central City Dweller Needing Regular Meals\n",
    "    persona_a_clients = combined_client_data[\n",
    "        (\n",
    "            combined_client_data[\"Distance from Paris Center\"]\n",
    "            <= combined_client_data[\"Distance from Paris Center\"].quantile(\n",
    "                0.25\n",
    "            )\n",
    "        )\n",
    "        & (combined_client_data[\"REPAS\"] > 0)\n",
    "    ].head()\n",
    "\n",
    "    # Persona B: Suburban Senior with Mobility Assistance Needs\n",
    "    persona_b_clients = combined_client_data[\n",
    "        (\n",
    "            combined_client_data[\"Distance from Paris Center\"]\n",
    "            > combined_client_data[\"Distance from Paris Center\"].quantile(0.25)\n",
    "        )\n",
    "        & (\n",
    "            combined_client_data[\"Distance from Paris Center\"]\n",
    "            <= combined_client_data[\"Distance from Paris Center\"].quantile(\n",
    "                0.75\n",
    "            )\n",
    "        )\n",
    "        & (combined_client_data[\"TOILETTE\"] > 0)\n",
    "    ].head()\n",
    "\n",
    "    # Persona C: Remote Client Needing Weekly Check-ins\n",
    "    persona_c_clients = combined_client_data[\n",
    "        (\n",
    "            combined_client_data[\"Distance from Paris Center\"]\n",
    "            > combined_client_data[\"Distance from Paris Center\"].quantile(0.75)\n",
    "        )\n",
    "        & (combined_client_data[\"REPAS\"] <= 2)\n",
    "    ].head()\n",
    "\n",
    "    jan24_df[\"Start Hour\"] = jan24_df[\"Heure de début\"].apply(lambda x: x.hour)\n",
    "    jan24_df[\"End Hour\"] = jan24_df[\"Heure de fin\"].apply(lambda x: x.hour)\n",
    "\n",
    "    # Persona E:  Adults Needing Evening Assistance (services post 5 PM)\n",
    "    persona_e_clients = (\n",
    "        jan24_df[jan24_df[\"Start Hour\"] >= 17][\"ID Client\"]\n",
    "        .value_counts()\n",
    "        .head()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    jan24_df[\"Day of Week\"] = jan24_df[\"Date\"].dt.dayofweek\n",
    "    # Persona F: Weekend Assistance Client (services on weekends)\n",
    "    persona_f_clients = (\n",
    "        jan24_df[jan24_df[\"Day of Week\"] >= 5][\"ID Client\"]\n",
    "        .value_counts()\n",
    "        .head()\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    # Persona H: Clients Needing Frequent Short Visits (Services less than or equal to 1 hour)\n",
    "    jan24_df[\"Service Duration\"] = (\n",
    "        jan24_df[\"End Hour\"] - jan24_df[\"Start Hour\"]\n",
    "    )\n",
    "    short_duration_clients = jan24_df[jan24_df[\"Service Duration\"] <= 1]\n",
    "    persona_h_clients = (\n",
    "        short_duration_clients[\"ID Client\"]\n",
    "        .value_counts()\n",
    "        .head()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    # Persona I: Early Morning Service Client (services before 8 AM)\n",
    "    early_morning_clients = jan24_df[jan24_df[\"Start Hour\"] < 8]\n",
    "    persona_i_clients = (\n",
    "        early_morning_clients[\"ID Client\"].value_counts().head().index.tolist()\n",
    "    )\n",
    "\n",
    "    # Persona J: High Frequency Care Recipient (multiple services throughout the day)\n",
    "    high_frequency_clients = jan24_df[\"ID Client\"].value_counts()\n",
    "    persona_j_clients = high_frequency_clients[\n",
    "        high_frequency_clients > high_frequency_clients.quantile(0.75)\n",
    "    ].index.tolist()[:5]\n",
    "    # Persona K: Infrequent, but Long Duration Visits (longer duration, fewer appointments)\n",
    "    long_duration_clients = jan24_df[\n",
    "        jan24_df[\"Service Duration\"]\n",
    "        > jan24_df[\"Service Duration\"].quantile(0.75)\n",
    "    ]\n",
    "    infrequent_long_duration_clients = long_duration_clients[\n",
    "        \"ID Client\"\n",
    "    ].value_counts()\n",
    "    persona_k_clients = infrequent_long_duration_clients[\n",
    "        infrequent_long_duration_clients\n",
    "        < infrequent_long_duration_clients.quantile(0.25)\n",
    "    ].index.tolist()[:5]\n",
    "\n",
    "    # Persona L: Clients with Varied Service Needs (diverse types of services)\n",
    "    varied_service_clients = client_service_summary[\n",
    "        client_service_summary > 0\n",
    "    ].count(axis=1)\n",
    "    persona_l_clients = varied_service_clients[\n",
    "        varied_service_clients > varied_service_clients.quantile(0.75)\n",
    "    ].index.tolist()[:5]\n",
    "\n",
    "    client_groups = {\n",
    "        \"a\": persona_a_clients[\"ID Client\"].to_list(),\n",
    "        \"b\": persona_b_clients[\"ID Client\"].to_list(),\n",
    "        \"c\": persona_c_clients[\"ID Client\"].to_list(),\n",
    "        \"e\": persona_e_clients,\n",
    "        \"f\": persona_f_clients,\n",
    "        \"h\": persona_h_clients,\n",
    "        \"i\": persona_i_clients,\n",
    "        \"j\": persona_j_clients,\n",
    "        \"k\": persona_k_clients,\n",
    "        \"l\": persona_l_clients,\n",
    "    }\n",
    "\n",
    "    clients_df[\"client_persona\"] = clients_df[\"ID Client\"].apply(\n",
    "        lambda x: find_key(client_groups, x)\n",
    "    )\n",
    "    return clients_df\n",
    "\n",
    "\n",
    "def generate_random_sessions(\n",
    "    persona_group: str,\n",
    "    df_client_with_persona: pd.DataFrame,\n",
    "    df_clients: pd.DataFrame,\n",
    "    df_sessions: pd.DataFrame,\n",
    "    df_caregivers: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Generate new clients and add it into the raw dataset.\n",
    "\n",
    "    Args:\n",
    "        persona_group (str): One of the possible persona segments created\n",
    "        df_client_with_persona (pd.DataFrame): Output from get_client_segments.\n",
    "            Similar to client sessions but contains persona column\n",
    "        df_clients (pd.DataFrame): raw clients data from excel sheet\n",
    "        df_sessions (pd.DataFrame): raw sessions data from excel sheet\n",
    "        df_caregivers (pd.DataFrame): raw caregivers data from excel sheet\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.DataFrame]: new client data and new sessions data\n",
    "    \"\"\"\n",
    "\n",
    "    df_persona = df_client_with_persona[\n",
    "        df_client_with_persona[\"client_persona\"] == persona_group\n",
    "    ].copy()\n",
    "\n",
    "    df = pd.merge(df_sessions, df_persona, how=\"left\", on=\"ID Client\")\n",
    "\n",
    "    # Generate event frequencies for the client persona\n",
    "    event_frequencies = (\n",
    "        df.groupby([\"client_persona\", \"Date\"])[\"Prestation\"].value_counts()\n",
    "        // 5\n",
    "        + 1\n",
    "    )\n",
    "\n",
    "    # Generate key for new client\n",
    "    new_client_id = np.random.randint(10000000, 100000000)\n",
    "\n",
    "    # Take a random location for client\n",
    "    client_loc = df_persona[[\"Latitude\", \"Longitude\"]].sample(1).to_dict()\n",
    "    client_loc = {k: list(v.values())[0] for k, v in client_loc.items()}\n",
    "\n",
    "    # Join new client to client dataset\n",
    "    new_client = pd.DataFrame(\n",
    "        {\"ID Client\": new_client_id} | client_loc, index=[len(df_clients)]\n",
    "    )\n",
    "    new_df_clients = pd.concat([df_clients, new_client])\n",
    "\n",
    "    # Get event freqs\n",
    "    freqs = event_frequencies.loc[persona_group].apply(\n",
    "        lambda x: max(1, x + np.random.randint(-1, 1))\n",
    "    )\n",
    "\n",
    "    # Generate a random event until all events are complete\n",
    "    new_events = pd.DataFrame(columns=df_sessions.columns)\n",
    "\n",
    "    ## Choose a random event start time\n",
    "    for (date, prest), count in freqs.to_frame().iterrows():\n",
    "        # display(i[1], count.iloc[0])\n",
    "        count = count.iloc[0]\n",
    "\n",
    "        times = df[df[\"Prestation\"] == prest][\n",
    "            [\"Heure de début\", \"Heure de fin\"]\n",
    "        ].sample(count)\n",
    "\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"ID Client\": [new_client_id] * count,\n",
    "                \"ID Intervenant\": [\n",
    "                    df_caregivers[\"ID Intervenant\"].sample(1).iloc[0]\n",
    "                ]\n",
    "                * count,\n",
    "                \"Date\": [date] * count,\n",
    "                \"Heure de début\": times[\"Heure de début\"].to_list(),\n",
    "                \"Heure de fin\": times[\"Heure de fin\"].to_list(),\n",
    "                \"Prestation\": [prest] * count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        new_events = pd.concat([new_events, new_row])\n",
    "\n",
    "    new_df_sessions = (\n",
    "        pd.concat([df_sessions, new_events])\n",
    "        .sort_values(by=\"Date\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return new_df_clients, new_df_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this to get new clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Clients\n",
    "df_clients = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=1)\n",
    "df_sessions = pd.read_excel(\"../data/ChallengeXHEC23022024.xlsx\", sheet_name=0)\n",
    "\n",
    "client_segments = get_client_segments()\n",
    "df_clients, df_sessions = generate_random_sessions(\n",
    "    \"a\",\n",
    "    client_segments,\n",
    "    df_clients,\n",
    "    df_sessions,\n",
    "    df_caregivers=intervenants_df,\n",
    ")\n",
    "df_clients, df_sessions = generate_random_sessions(\n",
    "    \"c\",\n",
    "    client_segments,\n",
    "    df_clients,\n",
    "    df_sessions,\n",
    "    df_caregivers=intervenants_df,\n",
    ")\n",
    "df_clients, df_sessions = generate_random_sessions(\n",
    "    \"h\",\n",
    "    client_segments,\n",
    "    df_clients,\n",
    "    df_sessions,\n",
    "    df_caregivers=intervenants_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "- Generate random scenarios of clients for n_clients equal to 1,2,3,4,5\n",
    "- Run the optimisation and see which ones have a feasible scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients, df_sessions = add_new_clients_and_sessions(\n",
    "    5,\n",
    "    excel_file=\"data/ChallengeXHEC23022024.xlsx\",\n",
    "    random_client_segment=False,\n",
    "    client_personas_sequence=\"13212\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_save_data(generate_new_clients=False, **{\"n_clients\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(include_availability=False, filter_for_competence=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
